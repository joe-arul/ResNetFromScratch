{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpZcHs124rHQ"
   },
   "source": [
    "## Build a CNN for Image Recognition.\n",
    "### Name: Joe Arul Susai Prakash (U34351756)\n",
    "### For class ISM6930 (Tech Foundation of AI) at the University of South Florida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trNtb6ToXZLU"
   },
   "source": [
    "### Summary of Results :\n",
    "\n",
    "\n",
    "- VGG16 architecture (__15 layers, 75 training epochs__) achieved __90.05%__ accuracy on test data with loss 0.317.\n",
    "- ResNet architecture (__48 layers, 35 training epochs__) achieved __82%__ accuracy on training before I ran out of compute units and lost access to the runtime and the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSVBNNPw5JQf"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOEUWW7HZuPT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLjb9m5i5Nte"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONcUKvP-j3zG",
    "outputId": "f37b8488-972a-465e-edf6-959f5b7aea07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 6s 0us/step\n",
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpHuIiqZ5-73"
   },
   "source": [
    "### One-hot encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXoNH31tWZcv"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "  num_labels = len(np.unique(labels))\n",
    "  one_hot_labels = np.zeros((len(labels), num_labels))\n",
    "  for i, label in enumerate(labels):\n",
    "    one_hot_labels[i, label] = 1\n",
    "  return one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lYKw7Mw6Dnz",
    "outputId": "d8a10562-55a8-427c-ab58-38613326eb97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_train_vec = one_hot_encode(y_train)\n",
    "y_test_vec = one_hot_encode(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWdcFParc62Q"
   },
   "source": [
    "### Randomly partition the training set to training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udKljmthc-S5",
    "outputId": "55ae882f-cf86-4432-844a-0d0a719daf07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = np.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf9bC4umdQzq"
   },
   "source": [
    "## Build a CNN and tune its hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQFggliudrBL"
   },
   "source": [
    "- Build a convolutional neural network model\n",
    "- Use the validation data to tune the hyper-parameters\n",
    "- Try to achieve a validation accuracy as high as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh8_3mT_nTc9"
   },
   "source": [
    "#### Model 1: Baseline model / LeNet Architecture (__10 epochs__)\n",
    "\n",
    "- 2 Convolution and Pooling layers\n",
    "- 1 Fully connected layer\n",
    "- RMSProp optimizer with learning rate = 0.00001\n",
    "- Batch size of train and val = 32\n",
    "\n",
    "__Validation accuracy at last epoch : 48.7%__\n",
    "\n",
    "__Validation Loss at last epoch : 1.61__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSx2DS9FdqD1",
    "outputId": "f43eff13-abb9-4f4a-d28e-bbfe22536a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               524416    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 545098 (2.08 MB)\n",
      "Trainable params: 545098 (2.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hr8pDwLJeK1K"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-5 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQ7LrRoeeX_W",
    "outputId": "bc1b41e0-8c7c-495e-901a-115d9aceae8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 14s 4ms/step - loss: 6.3495 - accuracy: 0.2112 - val_loss: 3.9476 - val_accuracy: 0.2736\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 3.3711 - accuracy: 0.3033 - val_loss: 2.9532 - val_accuracy: 0.3271\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.6523 - accuracy: 0.3461 - val_loss: 2.4919 - val_accuracy: 0.3585\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.2666 - accuracy: 0.3771 - val_loss: 2.1994 - val_accuracy: 0.3832\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.0182 - accuracy: 0.4046 - val_loss: 1.9976 - val_accuracy: 0.4077\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8441 - accuracy: 0.4317 - val_loss: 1.8837 - val_accuracy: 0.4293\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7161 - accuracy: 0.4559 - val_loss: 1.8006 - val_accuracy: 0.4427\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6193 - accuracy: 0.4756 - val_loss: 1.7541 - val_accuracy: 0.4496\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5414 - accuracy: 0.4940 - val_loss: 1.6560 - val_accuracy: 0.4742\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4741 - accuracy: 0.5128 - val_loss: 1.6144 - val_accuracy: 0.4873\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr, y_tr, batch_size=32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7lK-yIenYiz"
   },
   "source": [
    "#### Model 2: Baseline model with Data Augmentation (__10 epochs__)\n",
    "\n",
    "- 2 Convolution and Pooling layers\n",
    "- 1 Fully connected layer\n",
    "- __Data Augmentation on training data__\n",
    "- RMSProp optimizer with learning rate = 0.0001\n",
    "- Batch size of train and val = 32\n",
    "\n",
    "__Validation accuracy at last epoch : 54%__\n",
    "\n",
    "__Validation Loss at last epoch : 1.29__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yl6dMSHHoNUu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vucGaSyKnYMN",
    "outputId": "f05f12da-f3a0-44d8-ebca-2b47a9830989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               524416    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 545098 (2.08 MB)\n",
      "Trainable params: 545098 (2.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnDsrwZPzWqM"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cM-mWVTvzYgy"
   },
   "outputs": [],
   "source": [
    "train_datagen.fit(x_tr)\n",
    "val_datagen.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdXWrm0Czh4o",
    "outputId": "2056f8f6-cbc3-41b3-fd89-98683e6a7b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 30s 23ms/step - loss: 1.9580 - accuracy: 0.2964 - val_loss: 1.7268 - val_accuracy: 0.3893\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.7571 - accuracy: 0.3695 - val_loss: 1.5946 - val_accuracy: 0.4368\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.6834 - accuracy: 0.3959 - val_loss: 1.6905 - val_accuracy: 0.3981\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.6242 - accuracy: 0.4196 - val_loss: 1.4885 - val_accuracy: 0.4751\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5865 - accuracy: 0.4359 - val_loss: 1.3894 - val_accuracy: 0.5129\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5511 - accuracy: 0.4453 - val_loss: 1.4701 - val_accuracy: 0.4863\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5164 - accuracy: 0.4586 - val_loss: 1.3087 - val_accuracy: 0.5409\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.4867 - accuracy: 0.4694 - val_loss: 1.4992 - val_accuracy: 0.4647\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.4663 - accuracy: 0.4779 - val_loss: 1.3319 - val_accuracy: 0.5269\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.4448 - accuracy: 0.4851 - val_loss: 1.2908 - val_accuracy: 0.5401\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(train_datagen.flow(x_tr, y_tr, batch_size=32), validation_data=val_datagen.flow(x_val, y_val, batch_size=32), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jy81BVhMMDkY"
   },
   "source": [
    "#### Model 3: Baseline Model with Data Augmentation and Normalization layers (__10 epochs__)\n",
    "\n",
    "- 2 Convolution and Pooling layers\n",
    "- 1 Fully connected layer\n",
    "- Data Augmentation on training data\n",
    "- __Batch Normalization between hidden and activation layers__\n",
    "- RMSProp optimizer with learning rate = 0.00001\n",
    "- Batch size of train and val = 32\n",
    "\n",
    "__Validation accuracy at last epoch : 50.5%__\n",
    "\n",
    "__Validation Loss at last epoch : 1.417__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWiTTvJdMNsZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iaISE9OhMOYW",
    "outputId": "4c919ca8-ceb4-4a70-dc1c-521f7947e037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               524416    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 545994 (2.08 MB)\n",
      "Trainable params: 545546 (2.08 MB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model_3.add(layers.BatchNormalization())\n",
    "model_3.add(layers.Activation('relu'))\n",
    "model_3.add(MaxPooling2D((2, 2)))\n",
    "model_3.add(Conv2D(64, (3, 3),padding='same'))\n",
    "model_3.add(layers.BatchNormalization())\n",
    "model_3.add(layers.Activation('relu'))\n",
    "model_3.add(MaxPooling2D((2, 2)))\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(128))\n",
    "model_3.add(layers.BatchNormalization())\n",
    "model_3.add(layers.Activation('relu'))\n",
    "model_3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6doN4YdMRsM"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "#learning_rate = 1e-4\n",
    "\n",
    "learning_rate = 1e-5\n",
    "\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsfz8iaDNPhm"
   },
   "outputs": [],
   "source": [
    "train_datagen.fit(x_tr)\n",
    "val_datagen.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tbX8bcnINSqm",
    "outputId": "e68b20a4-a442-4df6-e635-e14a00e7ed27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 31s 23ms/step - loss: 2.0981 - accuracy: 0.2605 - val_loss: 1.8579 - val_accuracy: 0.3601\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.8451 - accuracy: 0.3406 - val_loss: 1.7377 - val_accuracy: 0.3947\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.7610 - accuracy: 0.3724 - val_loss: 1.6468 - val_accuracy: 0.4261\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.7090 - accuracy: 0.3864 - val_loss: 1.5915 - val_accuracy: 0.4425\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.6628 - accuracy: 0.4056 - val_loss: 1.5468 - val_accuracy: 0.4602\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.6341 - accuracy: 0.4173 - val_loss: 1.5085 - val_accuracy: 0.4742\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.6025 - accuracy: 0.4286 - val_loss: 1.4771 - val_accuracy: 0.4808\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5861 - accuracy: 0.4358 - val_loss: 1.4553 - val_accuracy: 0.4881\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5622 - accuracy: 0.4459 - val_loss: 1.4309 - val_accuracy: 0.4985\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.5486 - accuracy: 0.4485 - val_loss: 1.4179 - val_accuracy: 0.5054\n"
     ]
    }
   ],
   "source": [
    "history = model_3.fit(train_datagen.flow(x_tr, y_tr, batch_size=32), validation_data=val_datagen.flow(x_val, y_val, batch_size=8), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZqsVjOMQsDa"
   },
   "source": [
    "#### Model 4: Baseline Model with Data Augmentation, Normalization layers and Dropout layer (__25 epochs__)\n",
    "- 2 Convolution and Pooling layers\n",
    "- 1 Fully connected layer\n",
    "- Data Augmentation on training data\n",
    "- Batch Normalization between hidden and activation layers\n",
    "- __Dropout 50% before dense layer (epochs - 25) to avoid overfitting__\n",
    "- RMSProp optimizer with learning rate = 0.0001\n",
    "- Batch size of train and val = 32\n",
    "\n",
    "__Validation accuracy at last epoch : 56.3%__\n",
    "\n",
    "__Validation Loss at last epoch : 1.254__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKD7RpRXQ0Ah"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zevw2lccQ6Nz",
    "outputId": "93b4c384-3c37-4ba0-d3ca-7477876cdef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 32, 32, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               524416    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 545994 (2.08 MB)\n",
      "Trainable params: 545546 (2.08 MB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "model_4 = Sequential()\n",
    "model_4.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model_4.add(layers.BatchNormalization())\n",
    "model_4.add(layers.Activation('relu'))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Conv2D(64, (3, 3),padding='same'))\n",
    "model_4.add(layers.BatchNormalization())\n",
    "model_4.add(layers.Activation('relu'))\n",
    "model_4.add(MaxPooling2D((2, 2)))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(layers.Dropout(0.5))\n",
    "model_4.add(Dense(128))\n",
    "model_4.add(layers.BatchNormalization())\n",
    "model_4.add(layers.Activation('relu'))\n",
    "model_4.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9CrHKnGRAJ7"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "#learning_rate = 1e-4\n",
    "\n",
    "learning_rate = 1e-4\n",
    "\n",
    "model_4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rMdgODERA1s"
   },
   "outputs": [],
   "source": [
    "train_datagen.fit(x_tr)\n",
    "val_datagen.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sqkmvzRgRDSO",
    "outputId": "0d280443-b096-4536-9ef8-26df3a7efcf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1250/1250 [==============================] - 30s 22ms/step - loss: 1.9000 - accuracy: 0.3144 - val_loss: 1.6301 - val_accuracy: 0.4234\n",
      "Epoch 2/25\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.7006 - accuracy: 0.3871 - val_loss: 1.5075 - val_accuracy: 0.4613\n",
      "Epoch 3/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.6196 - accuracy: 0.4155 - val_loss: 1.4021 - val_accuracy: 0.4970\n",
      "Epoch 4/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.5724 - accuracy: 0.4339 - val_loss: 1.3574 - val_accuracy: 0.5165\n",
      "Epoch 5/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5310 - accuracy: 0.4478 - val_loss: 1.3426 - val_accuracy: 0.5244\n",
      "Epoch 6/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.5037 - accuracy: 0.4616 - val_loss: 1.2674 - val_accuracy: 0.5458\n",
      "Epoch 7/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.4733 - accuracy: 0.4734 - val_loss: 1.3388 - val_accuracy: 0.5333\n",
      "Epoch 8/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.4550 - accuracy: 0.4802 - val_loss: 1.3690 - val_accuracy: 0.5176\n",
      "Epoch 9/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.4381 - accuracy: 0.4867 - val_loss: 1.2688 - val_accuracy: 0.5503\n",
      "Epoch 10/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.4184 - accuracy: 0.4932 - val_loss: 1.4154 - val_accuracy: 0.5039\n",
      "Epoch 11/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.4065 - accuracy: 0.4966 - val_loss: 1.2677 - val_accuracy: 0.5509\n",
      "Epoch 12/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3921 - accuracy: 0.5038 - val_loss: 1.3357 - val_accuracy: 0.5173\n",
      "Epoch 13/25\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3786 - accuracy: 0.5069 - val_loss: 1.2153 - val_accuracy: 0.5662\n",
      "Epoch 14/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3711 - accuracy: 0.5098 - val_loss: 1.2555 - val_accuracy: 0.5541\n",
      "Epoch 15/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3609 - accuracy: 0.5170 - val_loss: 1.1801 - val_accuracy: 0.5732\n",
      "Epoch 16/25\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3470 - accuracy: 0.5199 - val_loss: 1.2706 - val_accuracy: 0.5471\n",
      "Epoch 17/25\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3443 - accuracy: 0.5209 - val_loss: 1.2467 - val_accuracy: 0.5620\n",
      "Epoch 18/25\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3271 - accuracy: 0.5228 - val_loss: 1.1578 - val_accuracy: 0.5972\n",
      "Epoch 19/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3183 - accuracy: 0.5295 - val_loss: 1.1110 - val_accuracy: 0.6011\n",
      "Epoch 20/25\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3080 - accuracy: 0.5318 - val_loss: 1.1931 - val_accuracy: 0.5792\n",
      "Epoch 21/25\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3120 - accuracy: 0.5320 - val_loss: 1.1485 - val_accuracy: 0.5980\n",
      "Epoch 22/25\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3030 - accuracy: 0.5390 - val_loss: 1.1684 - val_accuracy: 0.5927\n",
      "Epoch 23/25\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.2954 - accuracy: 0.5413 - val_loss: 1.1540 - val_accuracy: 0.5957\n",
      "Epoch 24/25\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.2948 - accuracy: 0.5418 - val_loss: 1.1265 - val_accuracy: 0.6009\n",
      "Epoch 25/25\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.2834 - accuracy: 0.5493 - val_loss: 1.2546 - val_accuracy: 0.5637\n"
     ]
    }
   ],
   "source": [
    "history = model_4.fit(train_datagen.flow(x_tr, y_tr), validation_data=val_datagen.flow(x_val, y_val),batch_size=32,epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIhyhftvYhh1"
   },
   "source": [
    "#### Model 5: __AlexNet Architecture (from scratch / 25 epochs)__\n",
    "Reference: https://www.kaggle.com/code/vortexkol/alexnet-cnn-architecture-on-tensorflow-beginner\n",
    "\n",
    "- 5 Convolution layers (2 with pooling)\n",
    "- 2 Fully connected layers\n",
    "- Data Augmentation on training data\n",
    "- Batch Normalization between hidden and activation layers\n",
    "- Dropout 50% before both dense layers (epochs - 25) to avoid overfitting\n",
    "- Adam optimizer with learning rate = 0.001\n",
    "- Batch size of train =32 and val = 8\n",
    "\n",
    "__Validation accuracy at last epoch : 72.1%__\n",
    "\n",
    "__Validation Loss at last epoch : 0.815__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ldi-qxJlhBz3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqE5SUtnatsF",
    "outputId": "29029056-dc80-419e-d7a1-4eb7cdae320c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 32, 32, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 5, 5, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 5, 5, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 5, 5, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 5, 5, 128)         0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 5, 5, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 5, 5, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 5, 5, 256)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 5, 5, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 5, 5, 256)         1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 5, 5, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 2, 2, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               131200    \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2168138 (8.27 MB)\n",
      "Trainable params: 2164362 (8.26 MB)\n",
      "Non-trainable params: 3776 (14.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "model_5 = Sequential()\n",
    "# Convolution 1 with pooling\n",
    "model_5.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model_5.add(layers.BatchNormalization())\n",
    "model_5.add(layers.Activation('relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Convolution 2 with pooling\n",
    "model_5.add(Conv2D(64, (3, 3),padding='same'))\n",
    "model_5.add(layers.BatchNormalization())\n",
    "model_5.add(layers.Activation('relu'))\n",
    "model_5.add(MaxPooling2D((3, 3)))\n",
    "\n",
    "# Convolution 3\n",
    "model_5.add(Conv2D(128, (3, 3),padding='same'))\n",
    "model_5.add(layers.BatchNormalization())\n",
    "model_5.add(layers.Activation('relu'))\n",
    "\n",
    "#Convolution 4\n",
    "model_5.add(Conv2D(256, (3, 3),padding='same'))\n",
    "model_5.add(layers.BatchNormalization())\n",
    "model_5.add(layers.Activation('relu'))\n",
    "\n",
    "# Convolution 5\n",
    "model_5.add(Conv2D(256, (3, 3),padding='same'))\n",
    "model_5.add(layers.BatchNormalization())\n",
    "model_5.add(layers.Activation('relu'))\n",
    "model_5.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model_5.add(Flatten())\n",
    "\n",
    "# Fully connected layer 1\n",
    "model_5.add(layers.Dropout(0.5))\n",
    "model_5.add(Dense(1024))\n",
    "model_5.add(layers.BatchNormalization())\n",
    "model_5.add(layers.Activation('relu'))\n",
    "\n",
    "# Fully connected layer 2\n",
    "model_5.add(layers.Dropout(0.5))\n",
    "model_5.add(Dense(128))\n",
    "model_5.add(layers.BatchNormalization())\n",
    "model_5.add(layers.Activation('relu'))\n",
    "\n",
    "model_5.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvzkxKF_g4V2"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "#learning_rate = 1e-4\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model_5.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_akF3B65hkN4"
   },
   "outputs": [],
   "source": [
    "train_datagen.fit(x_tr)\n",
    "val_datagen.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABvu-B0vhpW4",
    "outputId": "9a33fb4f-ea63-4306-bb75-57bef00c3c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1250/1250 [==============================] - 37s 25ms/step - loss: 1.7353 - accuracy: 0.3674 - val_loss: 1.5262 - val_accuracy: 0.4362\n",
      "Epoch 2/25\n",
      "1250/1250 [==============================] - 31s 24ms/step - loss: 1.4485 - accuracy: 0.4778 - val_loss: 1.6675 - val_accuracy: 0.4682\n",
      "Epoch 3/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 1.3214 - accuracy: 0.5276 - val_loss: 1.2632 - val_accuracy: 0.5614\n",
      "Epoch 4/25\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 1.2332 - accuracy: 0.5640 - val_loss: 1.2158 - val_accuracy: 0.5649\n",
      "Epoch 5/25\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 1.1726 - accuracy: 0.5869 - val_loss: 1.4052 - val_accuracy: 0.5441\n",
      "Epoch 6/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 1.1216 - accuracy: 0.6079 - val_loss: 1.3327 - val_accuracy: 0.5568\n",
      "Epoch 7/25\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 1.0712 - accuracy: 0.6237 - val_loss: 1.1926 - val_accuracy: 0.5987\n",
      "Epoch 8/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 1.0351 - accuracy: 0.6390 - val_loss: 0.8694 - val_accuracy: 0.6970\n",
      "Epoch 9/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9956 - accuracy: 0.6499 - val_loss: 0.8461 - val_accuracy: 0.7011\n",
      "Epoch 10/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9616 - accuracy: 0.6658 - val_loss: 0.9076 - val_accuracy: 0.6880\n",
      "Epoch 11/25\n",
      "1250/1250 [==============================] - 31s 24ms/step - loss: 0.9358 - accuracy: 0.6773 - val_loss: 1.0190 - val_accuracy: 0.6607\n",
      "Epoch 12/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.9122 - accuracy: 0.6839 - val_loss: 1.1920 - val_accuracy: 0.6140\n",
      "Epoch 13/25\n",
      "1250/1250 [==============================] - 31s 24ms/step - loss: 0.8939 - accuracy: 0.6895 - val_loss: 1.0827 - val_accuracy: 0.6482\n",
      "Epoch 14/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.8682 - accuracy: 0.7016 - val_loss: 0.8526 - val_accuracy: 0.7052\n",
      "Epoch 15/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.8532 - accuracy: 0.7057 - val_loss: 1.0441 - val_accuracy: 0.6596\n",
      "Epoch 16/25\n",
      "1250/1250 [==============================] - 31s 24ms/step - loss: 0.8376 - accuracy: 0.7097 - val_loss: 1.0498 - val_accuracy: 0.6442\n",
      "Epoch 17/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.8186 - accuracy: 0.7181 - val_loss: 0.7977 - val_accuracy: 0.7224\n",
      "Epoch 18/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.8109 - accuracy: 0.7197 - val_loss: 0.8887 - val_accuracy: 0.7050\n",
      "Epoch 19/25\n",
      "1250/1250 [==============================] - 31s 24ms/step - loss: 0.7900 - accuracy: 0.7268 - val_loss: 0.9864 - val_accuracy: 0.6804\n",
      "Epoch 20/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.7833 - accuracy: 0.7297 - val_loss: 0.8071 - val_accuracy: 0.7222\n",
      "Epoch 21/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.7700 - accuracy: 0.7347 - val_loss: 0.8244 - val_accuracy: 0.7176\n",
      "Epoch 22/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.7590 - accuracy: 0.7385 - val_loss: 0.6753 - val_accuracy: 0.7735\n",
      "Epoch 23/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.7504 - accuracy: 0.7397 - val_loss: 0.8977 - val_accuracy: 0.6956\n",
      "Epoch 24/25\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.7432 - accuracy: 0.7421 - val_loss: 0.8482 - val_accuracy: 0.7088\n",
      "Epoch 25/25\n",
      "1250/1250 [==============================] - 31s 24ms/step - loss: 0.7248 - accuracy: 0.7517 - val_loss: 0.8150 - val_accuracy: 0.7218\n"
     ]
    }
   ],
   "source": [
    "history = model_5.fit(train_datagen.flow(x_tr, y_tr, batch_size=32), validation_data=val_datagen.flow(x_val, y_val, batch_size=8),epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jttjcdQ0lfqT"
   },
   "outputs": [],
   "source": [
    "model_5.save('A2_Alexnet.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFCr86sylr8U"
   },
   "outputs": [],
   "source": [
    "model_to_use = tf.keras.models.load_model('A2_Alexnet.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNAV2xqT3kts"
   },
   "source": [
    "#### Model 6: __VGG16 Architecture (from scratch / 25 epochs)__\n",
    "Reference: https://builtin.com/machine-learning/vgg16\n",
    "\n",
    "- 13 Convolution layers (5 with pooling)\n",
    "- 2 Fully connected layers\n",
    "- Data Augmentation on training data\n",
    "- Batch Normalization between hidden and activation layers\n",
    "- Dropout 50% before both dense layers (epochs - 25) to avoid overfitting\n",
    "- Adam optimizer with learning rate = 0.001\n",
    "- Batch size of train =32 and val = 8\n",
    "\n",
    "__Validation accuracy at last epoch : 77%__\n",
    "\n",
    "__Validation Loss at last epoch : 0.707__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yK3BbpSqk6vC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avLNA_zsk7VD",
    "outputId": "1f29f2da-3a67-4ea0-8cc3-7cad0dcf477a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16, 16, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 16, 16, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 8, 8, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 8, 8, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 8, 8, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 4, 4, 512)         2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 4, 4, 512)         2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 4, 4, 512)         2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 2, 2, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 2, 2, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 2, 2, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 2, 2, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 1, 1, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              525312    \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16305482 (62.20 MB)\n",
      "Trainable params: 16293002 (62.15 MB)\n",
      "Non-trainable params: 12480 (48.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "model_6 = Sequential()\n",
    "# Convolution 1 with pooling\n",
    "model_6.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "\n",
    "# Convolution 2 with pooling\n",
    "model_6.add(Conv2D(64, (3, 3),padding='same'))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "model_6.add(MaxPooling2D((2, 2))) # pooling after conv 1,2\n",
    "\n",
    "# Convolution 3\n",
    "model_6.add(Conv2D(128, (3, 3),padding='same'))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "\n",
    "#Convolution 4\n",
    "model_6.add(Conv2D(128, (3, 3),padding='same'))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "model_6.add(MaxPooling2D((2, 2))) # pooling after conv 3,4\n",
    "\n",
    "# Convolution 5\n",
    "model_6.add(Conv2D(256, (3, 3),padding='same'))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "\n",
    "# Convolution 6\n",
    "model_6.add(Conv2D(256, (3, 3),padding='same'))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "\n",
    "# Convolution 7\n",
    "model_6.add(Conv2D(256, (3, 3),padding='same'))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "model_6.add(MaxPooling2D((2, 2))) # pooling after conv 5,6,7\n",
    "\n",
    "# Convolution 8\n",
    "model_6.add(Conv2D(512, (3, 3),padding='same'))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "\n",
    "# Convolution 9\n",
    "model_6.add(Conv2D(512, (3, 3),padding='same'))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "\n",
    "# Convolution 10\n",
    "model_6.add(Conv2D(512, (3, 3),padding='same'))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "model_6.add(MaxPooling2D((2, 2))) # pooling after conv 8,9,10\n",
    "\n",
    "# Convolution 11\n",
    "model_6.add(Conv2D(512, (3, 3),padding='same'))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "\n",
    "# Convolution 12\n",
    "model_6.add(Conv2D(512, (3, 3),padding='same'))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "\n",
    "# Convolution 13\n",
    "model_6.add(Conv2D(512, (3, 3),padding='same'))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "model_6.add(MaxPooling2D((2, 2))) # pooling after conv 11,12,13\n",
    "\n",
    "model_6.add(Flatten())\n",
    "\n",
    "# Fully connected layer 1\n",
    "model_6.add(layers.Dropout(0.5))\n",
    "model_6.add(Dense(1024))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "\n",
    "# Fully connected layer 2\n",
    "model_6.add(layers.Dropout(0.5))\n",
    "model_6.add(Dense(1024))\n",
    "model_6.add(layers.BatchNormalization())\n",
    "model_6.add(layers.Activation('relu'))\n",
    "\n",
    "model_6.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dkr4uCHJlFHa"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "#learning_rate = 1e-4\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model_6.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JRTccJblIpI"
   },
   "outputs": [],
   "source": [
    "train_datagen.fit(x_tr)\n",
    "val_datagen.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JaLQuixaEnB",
    "outputId": "5abbd083-7fa9-4625-fc7a-5eaa3fbe7168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1250/1250 [==============================] - 49s 23ms/step - loss: 2.1811 - accuracy: 0.1837 - val_loss: 3.0783 - val_accuracy: 0.1199\n",
      "Epoch 2/25\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 2.0506 - accuracy: 0.2076 - val_loss: 2.0024 - val_accuracy: 0.2111\n",
      "Epoch 3/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.9319 - accuracy: 0.2603 - val_loss: 2.1671 - val_accuracy: 0.2360\n",
      "Epoch 4/25\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.8293 - accuracy: 0.3094 - val_loss: 2.5702 - val_accuracy: 0.2464\n",
      "Epoch 5/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.7264 - accuracy: 0.3566 - val_loss: 1.6632 - val_accuracy: 0.4279\n",
      "Epoch 6/25\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.6444 - accuracy: 0.3905 - val_loss: 1.4879 - val_accuracy: 0.4311\n",
      "Epoch 7/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.5087 - accuracy: 0.4509 - val_loss: 1.4183 - val_accuracy: 0.4860\n",
      "Epoch 8/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.4082 - accuracy: 0.4950 - val_loss: 1.6250 - val_accuracy: 0.4749\n",
      "Epoch 9/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3133 - accuracy: 0.5345 - val_loss: 1.1317 - val_accuracy: 0.6047\n",
      "Epoch 10/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2523 - accuracy: 0.5627 - val_loss: 1.5757 - val_accuracy: 0.5184\n",
      "Epoch 11/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.1851 - accuracy: 0.5852 - val_loss: 1.2184 - val_accuracy: 0.6048\n",
      "Epoch 12/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.1333 - accuracy: 0.6087 - val_loss: 1.0760 - val_accuracy: 0.6428\n",
      "Epoch 13/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.0815 - accuracy: 0.6266 - val_loss: 0.9670 - val_accuracy: 0.6565\n",
      "Epoch 14/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 1.0316 - accuracy: 0.6468 - val_loss: 0.8392 - val_accuracy: 0.7142\n",
      "Epoch 15/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9866 - accuracy: 0.6630 - val_loss: 0.9456 - val_accuracy: 0.6948\n",
      "Epoch 16/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.9423 - accuracy: 0.6797 - val_loss: 1.0532 - val_accuracy: 0.6581\n",
      "Epoch 17/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.9065 - accuracy: 0.6926 - val_loss: 0.9212 - val_accuracy: 0.6917\n",
      "Epoch 18/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8755 - accuracy: 0.7039 - val_loss: 0.9443 - val_accuracy: 0.6845\n",
      "Epoch 19/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.8401 - accuracy: 0.7173 - val_loss: 0.8152 - val_accuracy: 0.7336\n",
      "Epoch 20/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8112 - accuracy: 0.7321 - val_loss: 0.7862 - val_accuracy: 0.7336\n",
      "Epoch 21/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7819 - accuracy: 0.7398 - val_loss: 0.6997 - val_accuracy: 0.7657\n",
      "Epoch 22/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7607 - accuracy: 0.7473 - val_loss: 0.6536 - val_accuracy: 0.7842\n",
      "Epoch 23/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.7325 - accuracy: 0.7582 - val_loss: 0.7641 - val_accuracy: 0.7465\n",
      "Epoch 24/25\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7091 - accuracy: 0.7643 - val_loss: 0.6446 - val_accuracy: 0.7807\n",
      "Epoch 25/25\n",
      "1250/1250 [==============================] - 28s 23ms/step - loss: 0.6861 - accuracy: 0.7741 - val_loss: 0.7077 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "history = model_6.fit(train_datagen.flow(x_tr, y_tr, batch_size=32), validation_data=val_datagen.flow(x_val, y_val, batch_size=8),epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ASqEjTarEjb"
   },
   "outputs": [],
   "source": [
    "model_6.save('A2_VGG16_U34351756.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfBnMbUEkH66"
   },
   "source": [
    "#### __Model 7: ResNet (from scratch / 10 epochs)__\n",
    "Reference : https://www.kaggle.com/code/mishki/resnet-keras-code-from-scratch-train-on-gpu\n",
    "- __48 layers__ in total (including 4 convolutions for identity)\n",
    "  - 3 layers in each identity block\n",
    "  - 4 layers in each convolution block\n",
    "  - 14 blocks stacked one by one\n",
    "  - No pooling after each convolution\n",
    "  - 1 FC layer with dropout\n",
    "- Data Augmentation on training data\n",
    "- Batch Normalization between hidden and activation layers\n",
    "- Dropout 50% before the dense layer to avoid overfitting\n",
    "- Adam optimizer with learning rate = 0.001\n",
    "- Batch size of train =32 and val = 8\n",
    "\n",
    "__Validation accuracy at last epoch : 63.4%__\n",
    "\n",
    "__Validation Loss at last epoch : 1.065__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvNgU32XxYRn"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kE_LZvNmxgAN"
   },
   "outputs": [],
   "source": [
    "train_datagen.fit(x_tr)\n",
    "val_datagen.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8vzlqUVpn8h"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, concatenate, GlobalAveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tyR4zcK7fel"
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, filter1, filter2, filter3):\n",
    "    # layer 1 of block\n",
    "    x = Conv2D(filter1, (1, 1), padding=\"same\")(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # layer 2 of block\n",
    "    x = Conv2D(filter2, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # layer 3 of block\n",
    "    x = Conv2D(filter3, (1, 1), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Add the residual connection\n",
    "    x = concatenate([x, input_tensor])\n",
    "    x = ReLU()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hzKJlKp7gNl"
   },
   "outputs": [],
   "source": [
    "def convolution_block(input_tensor, filter1, filter2, filter3):\n",
    "    # layer 1 of block\n",
    "    x = Conv2D(filter1, (1, 1), padding=\"same\")(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # layer 2 of block\n",
    "    x = Conv2D(filter2, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # layer 3 of block\n",
    "    x = Conv2D(filter3, (1, 1), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # convolution for residual layer\n",
    "    residual = Conv2D(filter3, (1, 1), padding=\"same\")(input_tensor)\n",
    "    residual = BatchNormalization()(residual)\n",
    "    x = concatenate([x, residual])\n",
    "    x = ReLU()(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mv4wndUS7tTL"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Model initialization\n",
    "model_7 = Sequential()\n",
    "\n",
    "# Convolution 1 with pooling\n",
    "model_7.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(ReLU())\n",
    "\n",
    "# Level 1 (3 blocks)\n",
    "x = convolution_block(model_7.layers[-1].output, 32, 32, 64)\n",
    "x = identity_block(x, 64, 64, 128)\n",
    "x = identity_block(x, 64, 64, 128)\n",
    "\n",
    "# Level 2 (3 blocks)\n",
    "x = convolution_block(x, 128, 128, 256)\n",
    "x = identity_block(x, 128, 128, 256)\n",
    "x = identity_block(x, 256, 256, 512)\n",
    "\n",
    "# Level 3 (5 blocks)\n",
    "x = convolution_block(x, 256, 256, 512)\n",
    "x = identity_block(x, 256, 256, 512)\n",
    "x = identity_block(x, 512, 512, 1024)\n",
    "x = identity_block(x, 512, 512, 1024)\n",
    "x = identity_block(x, 512, 512, 1024)\n",
    "\n",
    "# Level 4 (3 blocks)\n",
    "x = convolution_block(x, 512, 512, 1024)\n",
    "x = identity_block(x, 512, 512, 1024)\n",
    "x = identity_block(x, 512, 512, 1024)\n",
    "\n",
    "# Final pooling\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Fully connected layer 1\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = Dense(1024)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# Output Layer\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model_7 = Model(inputs=model_7.inputs, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBVZHAsBxjbH"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "#learning_rate = 1e-4\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model_7.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Zx1jo3x8FSo",
    "outputId": "504a1b91-4abc-4e29-915e-2a4255cacb77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 272s 178ms/step - loss: 2.0002 - accuracy: 0.2768 - val_loss: 2.7585 - val_accuracy: 0.3240\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 221s 177ms/step - loss: 1.7562 - accuracy: 0.3687 - val_loss: 6.5839 - val_accuracy: 0.2529\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 221s 177ms/step - loss: 1.6550 - accuracy: 0.4073 - val_loss: 8.9791 - val_accuracy: 0.2239\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 221s 177ms/step - loss: 1.4910 - accuracy: 0.4590 - val_loss: 1.6410 - val_accuracy: 0.4454\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 221s 177ms/step - loss: 1.3790 - accuracy: 0.5026 - val_loss: 2.1400 - val_accuracy: 0.4088\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 222s 177ms/step - loss: 1.3052 - accuracy: 0.5297 - val_loss: 1.5484 - val_accuracy: 0.4819\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 222s 177ms/step - loss: 1.2409 - accuracy: 0.5556 - val_loss: 2.2513 - val_accuracy: 0.3996\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 222s 177ms/step - loss: 1.1843 - accuracy: 0.5773 - val_loss: 1.7656 - val_accuracy: 0.4939\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 222s 178ms/step - loss: 1.1141 - accuracy: 0.6044 - val_loss: 1.3609 - val_accuracy: 0.5569\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 222s 177ms/step - loss: 1.0593 - accuracy: 0.6252 - val_loss: 1.0654 - val_accuracy: 0.6346\n"
     ]
    }
   ],
   "source": [
    "history = model_7.fit(train_datagen.flow(x_tr, y_tr, batch_size=32), validation_data=val_datagen.flow(x_val, y_val, batch_size=8),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oV9LiNA9GTA5"
   },
   "outputs": [],
   "source": [
    "model_7.save('A2_ResNet_U34351756.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSuWBIvOHMmW"
   },
   "source": [
    "## Train (again) and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgY1ha5RHvfc"
   },
   "source": [
    "### Train the model on the entire training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JecwgqHXH0Yi"
   },
   "source": [
    "#### __Based on previous iterations of training, VGG16 and ResNet architectures seem to perform better than other versions. I will be training both these models with the entire training set (changing 1 hyperparameter - epochs) and evaluate them on the test set__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjChYxi6ISjy"
   },
   "source": [
    "#### VGG16 (model 6) Re-training with same architecture (epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifCfuziCJXbl"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# entire training set\n",
    "train_datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HlGGImNVJcsK"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "#learning_rate = 1e-4\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model_6.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wbmt68QJnPP",
    "outputId": "cebb5bf7-ac5e-4375-f9b5-31aac7e2580c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 44s 22ms/step - loss: 2.0989 - accuracy: 0.2051\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.8620 - accuracy: 0.2808\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.6748 - accuracy: 0.3703\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.4820 - accuracy: 0.4599\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.3467 - accuracy: 0.5204\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.2284 - accuracy: 0.5679\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.1347 - accuracy: 0.6067\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.0604 - accuracy: 0.6328\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.9998 - accuracy: 0.6559\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.9430 - accuracy: 0.6807\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.8954 - accuracy: 0.6988\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.8460 - accuracy: 0.7162\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.8083 - accuracy: 0.7311\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.7669 - accuracy: 0.7443\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.7330 - accuracy: 0.7591\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.7050 - accuracy: 0.7692\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.6805 - accuracy: 0.7761\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.6557 - accuracy: 0.7845\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.6350 - accuracy: 0.7895\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.6084 - accuracy: 0.8021\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.5882 - accuracy: 0.8055\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.5753 - accuracy: 0.8105\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.5621 - accuracy: 0.8162\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.5436 - accuracy: 0.8224\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.5325 - accuracy: 0.8271\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.5172 - accuracy: 0.8323\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.5028 - accuracy: 0.8372\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.4864 - accuracy: 0.8410\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.4738 - accuracy: 0.8459\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.4642 - accuracy: 0.8497\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.4599 - accuracy: 0.8494\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.4521 - accuracy: 0.8527\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.4326 - accuracy: 0.8576\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.4298 - accuracy: 0.8609\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.4248 - accuracy: 0.8611\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.4133 - accuracy: 0.8654\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3984 - accuracy: 0.8699\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3995 - accuracy: 0.8699\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3955 - accuracy: 0.8717\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.3838 - accuracy: 0.8748\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 0.3762 - accuracy: 0.8771\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3767 - accuracy: 0.8783\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3632 - accuracy: 0.8807\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.3586 - accuracy: 0.8832\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.3459 - accuracy: 0.8869\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3509 - accuracy: 0.8869\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.3426 - accuracy: 0.8882\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3382 - accuracy: 0.8900\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3280 - accuracy: 0.8936\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3273 - accuracy: 0.8930\n"
     ]
    }
   ],
   "source": [
    "history = model_6.fit(train_datagen.flow(x_train, y_train_vec, batch_size=32),epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zL8XILXhSwee"
   },
   "outputs": [],
   "source": [
    "model_6.save('A2_VGG16_U34351756_Final1.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMapcvWXSIyr"
   },
   "source": [
    "#### ResNet (model 7) Re-training with same architecture (epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2OS8y1bJRgU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# entire training set\n",
    "train_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3P28wLGcVMMm"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "#learning_rate = 1e-4\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model_7.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLoqSGUoVRY2",
    "outputId": "e3be43d3-5d46-4ec2-ba37-1d1e44c5db0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1563/1563 [==============================] - 288s 166ms/step - loss: 1.9630 - accuracy: 0.2803\n",
      "Epoch 2/25\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 1.7464 - accuracy: 0.3738\n",
      "Epoch 3/25\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 1.5930 - accuracy: 0.4269\n",
      "Epoch 4/25\n",
      "1563/1563 [==============================] - 255s 163ms/step - loss: 1.4578 - accuracy: 0.4760\n",
      "Epoch 5/25\n",
      "1563/1563 [==============================] - 255s 163ms/step - loss: 1.3447 - accuracy: 0.5159\n",
      "Epoch 6/25\n",
      "1563/1563 [==============================] - 255s 163ms/step - loss: 1.2451 - accuracy: 0.5548\n",
      "Epoch 7/25\n",
      "1563/1563 [==============================] - 255s 163ms/step - loss: 1.1618 - accuracy: 0.5853\n",
      "Epoch 8/25\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 1.1096 - accuracy: 0.6047\n",
      "Epoch 9/25\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 1.0534 - accuracy: 0.6250\n",
      "Epoch 10/25\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 1.0037 - accuracy: 0.6460\n",
      "Epoch 11/25\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 0.9643 - accuracy: 0.6594\n",
      "Epoch 12/25\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 0.9288 - accuracy: 0.6744\n",
      "Epoch 13/25\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 0.8873 - accuracy: 0.6895\n",
      "Epoch 14/25\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 0.8569 - accuracy: 0.6981\n",
      "Epoch 15/25\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 0.8333 - accuracy: 0.7079\n",
      "Epoch 16/25\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 0.8020 - accuracy: 0.7186\n",
      "Epoch 17/25\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 0.7754 - accuracy: 0.7307\n",
      "Epoch 18/25\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 0.7507 - accuracy: 0.7390\n",
      "Epoch 19/25\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 0.7277 - accuracy: 0.7453\n",
      "Epoch 20/25\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 0.7045 - accuracy: 0.7554\n",
      "Epoch 21/25\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 0.6821 - accuracy: 0.7630\n",
      "Epoch 22/25\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 0.6688 - accuracy: 0.7687\n",
      "Epoch 23/25\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 0.6504 - accuracy: 0.7735\n",
      "Epoch 24/25\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 0.6356 - accuracy: 0.7802\n",
      "Epoch 25/25\n",
      "1563/1563 [==============================] - 255s 163ms/step - loss: 0.6187 - accuracy: 0.7840\n"
     ]
    }
   ],
   "source": [
    "history = model_7.fit(train_datagen.flow(x_train, y_train_vec, batch_size=32),epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MW9fT8s_y_pc"
   },
   "source": [
    "##### Model training is progressing very slowly - maybe a better learning rate would have improved the training process as mentioned here.\n",
    "https://pyimagesearch.com/2019/09/23/keras-starting-stopping-and-resuming-training/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8TMuV7w0VfC"
   },
   "source": [
    "#### ResNet (model 7) Re-training with same architecture but a different learning rate (epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IY-hoApo0j3m"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# entire training set\n",
    "train_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGUWkFKs0sTW"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "#learning_rate = 1e-4\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "model_7.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ANA8Upn0wgB",
    "outputId": "7ea7b84f-7fad-44bc-ff4f-b45122ef07ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 284s 162ms/step - loss: 2.1477 - accuracy: 0.2294\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 1.7922 - accuracy: 0.3270\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 1.5967 - accuracy: 0.4145\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 1.4653 - accuracy: 0.4666\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 254s 163ms/step - loss: 1.3762 - accuracy: 0.5005\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 1.2989 - accuracy: 0.5305\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 1.2330 - accuracy: 0.5593\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 1.1743 - accuracy: 0.5798\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 1.1249 - accuracy: 0.5982\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 1.0759 - accuracy: 0.6211\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 1.0263 - accuracy: 0.6394\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.9841 - accuracy: 0.6528\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.9445 - accuracy: 0.6683\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.9126 - accuracy: 0.6814\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.8866 - accuracy: 0.6899\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.8591 - accuracy: 0.7019\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.8237 - accuracy: 0.7142\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 0.7983 - accuracy: 0.7212\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.7733 - accuracy: 0.7328\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 0.7514 - accuracy: 0.7400\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.7276 - accuracy: 0.7485\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.7069 - accuracy: 0.7552\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.6808 - accuracy: 0.7649\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.6678 - accuracy: 0.7696\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.6474 - accuracy: 0.7769\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.6358 - accuracy: 0.7812\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.6153 - accuracy: 0.7887\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 0.6034 - accuracy: 0.7925\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.5900 - accuracy: 0.7969\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.5824 - accuracy: 0.8004\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.5681 - accuracy: 0.8043\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.5539 - accuracy: 0.8091\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.5414 - accuracy: 0.8142\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.5301 - accuracy: 0.8184\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.5224 - accuracy: 0.8225\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 253s 162ms/step - loss: 0.5062 - accuracy: 0.8260\n",
      "Epoch 37/50\n",
      "1245/1563 [======================>.......] - ETA: 51s - loss: 0.5031 - accuracy: 0.8290"
     ]
    }
   ],
   "source": [
    "history = model_7.fit(train_datagen.flow(x_train, y_train_vec, batch_size=32),epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-u5jr4IbRq31"
   },
   "source": [
    "##### __Lost connectivity__ :)\n",
    "So I exhausted my compute units for the month for the A100 NVIDIA GPUs. In the last few epochs the accuracy improvement has slowed down to around 0.4% - which means that it will take a lot more iterations to converge to even 90%.\n",
    "The Tesla T4 GPU takes 42 minutes to complete 1 epoch as opposed to just 4 minutes for 1 epoch on the A100s. So I'm stopping training for this model here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqBmA03w7zts"
   },
   "source": [
    "#### VGG16 (model 6) Re-training with same architecture (epochs = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzF6RYO_71h0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# entire training set\n",
    "train_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UBljzjw7zUu"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "#learning_rate = 1e-4\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model_6.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXoWEiCT8ICk",
    "outputId": "3d7ca32e-78cd-47a6-c8b6-d6878511b7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "1563/1563 [==============================] - 43s 21ms/step - loss: 2.0789 - accuracy: 0.2104\n",
      "Epoch 2/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 1.8831 - accuracy: 0.2821\n",
      "Epoch 3/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.7189 - accuracy: 0.3486\n",
      "Epoch 4/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 1.5728 - accuracy: 0.4098\n",
      "Epoch 5/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 1.4231 - accuracy: 0.4890\n",
      "Epoch 6/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 1.2810 - accuracy: 0.5483\n",
      "Epoch 7/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 1.1837 - accuracy: 0.5897\n",
      "Epoch 8/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 1.0935 - accuracy: 0.6218\n",
      "Epoch 9/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.0323 - accuracy: 0.6474\n",
      "Epoch 10/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.9694 - accuracy: 0.6694\n",
      "Epoch 11/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.9226 - accuracy: 0.6879\n",
      "Epoch 12/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.8706 - accuracy: 0.7089\n",
      "Epoch 13/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.8330 - accuracy: 0.7207\n",
      "Epoch 14/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.7891 - accuracy: 0.7357\n",
      "Epoch 15/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.7609 - accuracy: 0.7468\n",
      "Epoch 16/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.7222 - accuracy: 0.7595\n",
      "Epoch 17/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.6964 - accuracy: 0.7705\n",
      "Epoch 18/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.6670 - accuracy: 0.7811\n",
      "Epoch 19/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.6486 - accuracy: 0.7864\n",
      "Epoch 20/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.6352 - accuracy: 0.7925\n",
      "Epoch 21/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.6071 - accuracy: 0.8005\n",
      "Epoch 22/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.5861 - accuracy: 0.8072\n",
      "Epoch 23/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.5729 - accuracy: 0.8123\n",
      "Epoch 24/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.5602 - accuracy: 0.8182\n",
      "Epoch 25/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.5478 - accuracy: 0.8220\n",
      "Epoch 26/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.5287 - accuracy: 0.8269\n",
      "Epoch 27/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.5154 - accuracy: 0.8306\n",
      "Epoch 28/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.4965 - accuracy: 0.8363\n",
      "Epoch 29/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.4915 - accuracy: 0.8394\n",
      "Epoch 30/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4742 - accuracy: 0.8449\n",
      "Epoch 31/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4636 - accuracy: 0.8481\n",
      "Epoch 32/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4509 - accuracy: 0.8526\n",
      "Epoch 33/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4430 - accuracy: 0.8548\n",
      "Epoch 34/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4264 - accuracy: 0.8587\n",
      "Epoch 35/75\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4261 - accuracy: 0.8602\n",
      "Epoch 36/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.4108 - accuracy: 0.8664\n",
      "Epoch 37/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.4005 - accuracy: 0.8685\n",
      "Epoch 38/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.4009 - accuracy: 0.8674\n",
      "Epoch 39/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3873 - accuracy: 0.8718\n",
      "Epoch 40/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3835 - accuracy: 0.8731\n",
      "Epoch 41/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3801 - accuracy: 0.8748\n",
      "Epoch 42/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.3667 - accuracy: 0.8796\n",
      "Epoch 43/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.3670 - accuracy: 0.8789\n",
      "Epoch 44/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3580 - accuracy: 0.8818\n",
      "Epoch 45/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3551 - accuracy: 0.8845\n",
      "Epoch 46/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3442 - accuracy: 0.8858\n",
      "Epoch 47/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3375 - accuracy: 0.8895\n",
      "Epoch 48/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.3361 - accuracy: 0.8897\n",
      "Epoch 49/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.3357 - accuracy: 0.8887\n",
      "Epoch 50/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3334 - accuracy: 0.8915\n",
      "Epoch 51/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.3180 - accuracy: 0.8957\n",
      "Epoch 52/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3157 - accuracy: 0.8956\n",
      "Epoch 53/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3105 - accuracy: 0.8978\n",
      "Epoch 54/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3042 - accuracy: 0.9004\n",
      "Epoch 55/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3029 - accuracy: 0.9011\n",
      "Epoch 56/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3012 - accuracy: 0.8999\n",
      "Epoch 57/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2970 - accuracy: 0.9019\n",
      "Epoch 58/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2946 - accuracy: 0.9028\n",
      "Epoch 59/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2829 - accuracy: 0.9055\n",
      "Epoch 60/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2863 - accuracy: 0.9049\n",
      "Epoch 61/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2837 - accuracy: 0.9071\n",
      "Epoch 62/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2777 - accuracy: 0.9094\n",
      "Epoch 63/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2749 - accuracy: 0.9094\n",
      "Epoch 64/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2703 - accuracy: 0.9105\n",
      "Epoch 65/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2703 - accuracy: 0.9092\n",
      "Epoch 66/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.2688 - accuracy: 0.9130\n",
      "Epoch 67/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2577 - accuracy: 0.9152\n",
      "Epoch 68/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2571 - accuracy: 0.9151\n",
      "Epoch 69/75\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.2538 - accuracy: 0.9168\n",
      "Epoch 70/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2486 - accuracy: 0.9164\n",
      "Epoch 71/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2480 - accuracy: 0.9187\n",
      "Epoch 72/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2449 - accuracy: 0.9205\n",
      "Epoch 73/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2408 - accuracy: 0.9203\n",
      "Epoch 74/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2418 - accuracy: 0.9208\n",
      "Epoch 75/75\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2400 - accuracy: 0.9205\n"
     ]
    }
   ],
   "source": [
    "history = model_6.fit(train_datagen.flow(x_train, y_train_vec, batch_size=32),epochs=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBAZecc5G1p6"
   },
   "outputs": [],
   "source": [
    "model_6.save('A2_VGG16_U34351756_Final2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XfSw9Mfcx_n"
   },
   "source": [
    "#### VGG16 (model 6) Re-training with same architecture (epochs = 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXlC400Rc7Nd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# entire training set\n",
    "train_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYexHffXc763"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "#learning_rate = 1e-4\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model_6.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1FBQpBBc_dS",
    "outputId": "5c9e4902-0e77-4ebe-ee27-ccdb1834c387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "1563/1563 [==============================] - 67s 29ms/step - loss: 2.1100 - accuracy: 0.2010\n",
      "Epoch 2/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.8460 - accuracy: 0.2922\n",
      "Epoch 3/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.6733 - accuracy: 0.3682\n",
      "Epoch 4/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.5501 - accuracy: 0.4283\n",
      "Epoch 5/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.4135 - accuracy: 0.4968\n",
      "Epoch 6/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 1.2956 - accuracy: 0.5483\n",
      "Epoch 7/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.1927 - accuracy: 0.5915\n",
      "Epoch 8/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.1072 - accuracy: 0.6182\n",
      "Epoch 9/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 1.0312 - accuracy: 0.6459\n",
      "Epoch 10/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.9741 - accuracy: 0.6666\n",
      "Epoch 11/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.9220 - accuracy: 0.6873\n",
      "Epoch 12/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.8753 - accuracy: 0.7046\n",
      "Epoch 13/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.8323 - accuracy: 0.7204\n",
      "Epoch 14/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.7934 - accuracy: 0.7379\n",
      "Epoch 15/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.7586 - accuracy: 0.7506\n",
      "Epoch 16/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.7254 - accuracy: 0.7595\n",
      "Epoch 17/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.6952 - accuracy: 0.7690\n",
      "Epoch 18/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.6705 - accuracy: 0.7785\n",
      "Epoch 19/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.6551 - accuracy: 0.7841\n",
      "Epoch 20/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.6317 - accuracy: 0.7919\n",
      "Epoch 21/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5989 - accuracy: 0.8028\n",
      "Epoch 22/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5869 - accuracy: 0.8074\n",
      "Epoch 23/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5695 - accuracy: 0.8132\n",
      "Epoch 24/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5560 - accuracy: 0.8180\n",
      "Epoch 25/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5377 - accuracy: 0.8246\n",
      "Epoch 26/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5268 - accuracy: 0.8277\n",
      "Epoch 27/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5120 - accuracy: 0.8325\n",
      "Epoch 28/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4988 - accuracy: 0.8361\n",
      "Epoch 29/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4898 - accuracy: 0.8412\n",
      "Epoch 30/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4781 - accuracy: 0.8447\n",
      "Epoch 31/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4662 - accuracy: 0.8483\n",
      "Epoch 32/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4523 - accuracy: 0.8518\n",
      "Epoch 33/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.4369 - accuracy: 0.8554\n",
      "Epoch 34/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4345 - accuracy: 0.8579\n",
      "Epoch 35/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4263 - accuracy: 0.8629\n",
      "Epoch 36/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4218 - accuracy: 0.8638\n",
      "Epoch 37/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4123 - accuracy: 0.8665\n",
      "Epoch 38/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4023 - accuracy: 0.8687\n",
      "Epoch 39/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.3955 - accuracy: 0.8716\n",
      "Epoch 40/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.3881 - accuracy: 0.8735\n",
      "Epoch 41/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3801 - accuracy: 0.8754\n",
      "Epoch 42/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3739 - accuracy: 0.8787\n",
      "Epoch 43/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3666 - accuracy: 0.8797\n",
      "Epoch 44/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3617 - accuracy: 0.8826\n",
      "Epoch 45/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3564 - accuracy: 0.8830\n",
      "Epoch 46/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3484 - accuracy: 0.8847\n",
      "Epoch 47/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3438 - accuracy: 0.8875\n",
      "Epoch 48/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3385 - accuracy: 0.8893\n",
      "Epoch 49/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3283 - accuracy: 0.8928\n",
      "Epoch 50/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3251 - accuracy: 0.8943\n",
      "Epoch 51/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3219 - accuracy: 0.8950\n",
      "Epoch 52/125\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.3180 - accuracy: 0.8959\n",
      "Epoch 53/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3127 - accuracy: 0.8966\n",
      "Epoch 54/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3086 - accuracy: 0.8985\n",
      "Epoch 55/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.3038 - accuracy: 0.9009\n",
      "Epoch 56/125\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.2946 - accuracy: 0.9037\n",
      "Epoch 57/125\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.2954 - accuracy: 0.9033\n",
      "Epoch 58/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2875 - accuracy: 0.9056\n",
      "Epoch 59/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2873 - accuracy: 0.9045\n",
      "Epoch 60/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2893 - accuracy: 0.9049\n",
      "Epoch 61/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2851 - accuracy: 0.9067\n",
      "Epoch 62/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2778 - accuracy: 0.9087\n",
      "Epoch 63/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2702 - accuracy: 0.9120\n",
      "Epoch 64/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2733 - accuracy: 0.9103\n",
      "Epoch 65/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2580 - accuracy: 0.9146\n",
      "Epoch 66/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2619 - accuracy: 0.9127\n",
      "Epoch 67/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2560 - accuracy: 0.9157\n",
      "Epoch 68/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2622 - accuracy: 0.9140\n",
      "Epoch 69/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2561 - accuracy: 0.9153\n",
      "Epoch 70/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2541 - accuracy: 0.9162\n",
      "Epoch 71/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2457 - accuracy: 0.9187\n",
      "Epoch 72/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2460 - accuracy: 0.9178\n",
      "Epoch 73/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2460 - accuracy: 0.9200\n",
      "Epoch 74/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2329 - accuracy: 0.9249\n",
      "Epoch 75/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2367 - accuracy: 0.9213\n",
      "Epoch 76/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2320 - accuracy: 0.9239\n",
      "Epoch 77/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2316 - accuracy: 0.9238\n",
      "Epoch 78/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2297 - accuracy: 0.9249\n",
      "Epoch 79/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2296 - accuracy: 0.9242\n",
      "Epoch 80/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2197 - accuracy: 0.9265\n",
      "Epoch 81/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2280 - accuracy: 0.9248\n",
      "Epoch 82/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2173 - accuracy: 0.9285\n",
      "Epoch 83/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2131 - accuracy: 0.9288\n",
      "Epoch 84/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2108 - accuracy: 0.9315\n",
      "Epoch 85/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2129 - accuracy: 0.9300\n",
      "Epoch 86/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2101 - accuracy: 0.9308\n",
      "Epoch 87/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2066 - accuracy: 0.9315\n",
      "Epoch 88/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2054 - accuracy: 0.9319\n",
      "Epoch 89/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2022 - accuracy: 0.9333\n",
      "Epoch 90/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.2058 - accuracy: 0.9333\n",
      "Epoch 91/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1999 - accuracy: 0.9333\n",
      "Epoch 92/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1996 - accuracy: 0.9340\n",
      "Epoch 93/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.1966 - accuracy: 0.9351\n",
      "Epoch 94/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1994 - accuracy: 0.9345\n",
      "Epoch 95/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.1929 - accuracy: 0.9368\n",
      "Epoch 96/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.1941 - accuracy: 0.9360\n",
      "Epoch 97/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.1950 - accuracy: 0.9352\n",
      "Epoch 98/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.1904 - accuracy: 0.9368\n",
      "Epoch 99/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1891 - accuracy: 0.9375\n",
      "Epoch 100/125\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.1922 - accuracy: 0.9376\n",
      "Epoch 101/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1804 - accuracy: 0.9412\n",
      "Epoch 102/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1795 - accuracy: 0.9408\n",
      "Epoch 103/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1843 - accuracy: 0.9394\n",
      "Epoch 104/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1760 - accuracy: 0.9421\n",
      "Epoch 105/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1782 - accuracy: 0.9421\n",
      "Epoch 106/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1787 - accuracy: 0.9406\n",
      "Epoch 107/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1789 - accuracy: 0.9413\n",
      "Epoch 108/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1751 - accuracy: 0.9422\n",
      "Epoch 109/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1708 - accuracy: 0.9434\n",
      "Epoch 110/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1729 - accuracy: 0.9432\n",
      "Epoch 111/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1677 - accuracy: 0.9451\n",
      "Epoch 112/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1623 - accuracy: 0.9457\n",
      "Epoch 113/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1693 - accuracy: 0.9441\n",
      "Epoch 114/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1641 - accuracy: 0.9461\n",
      "Epoch 115/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1658 - accuracy: 0.9463\n",
      "Epoch 116/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1612 - accuracy: 0.9473\n",
      "Epoch 117/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1618 - accuracy: 0.9471\n",
      "Epoch 118/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1660 - accuracy: 0.9454\n",
      "Epoch 119/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1597 - accuracy: 0.9478\n",
      "Epoch 120/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1609 - accuracy: 0.9475\n",
      "Epoch 121/125\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.1588 - accuracy: 0.9477\n",
      "Epoch 122/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1547 - accuracy: 0.9489\n",
      "Epoch 123/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1552 - accuracy: 0.9491\n",
      "Epoch 124/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1531 - accuracy: 0.9499\n",
      "Epoch 125/125\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.1498 - accuracy: 0.9505\n"
     ]
    }
   ],
   "source": [
    "history = model_6.fit(train_datagen.flow(x_train, y_train_vec, batch_size=32),epochs=125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4lL4vJx9cw0"
   },
   "source": [
    "##### This model (125 epochs) does __not__ produce the highest accuracy with the test set (89%). The 75 epoch version does better (90%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUuVWqNzSVvb"
   },
   "source": [
    "### Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQori06ISbVy"
   },
   "source": [
    "#### VGG16 architecture - 50 epochs (model 6 performance on test set)\n",
    "#### __Accuracy = 90.04%, Loss=0.317__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YEvQWgcSp2U"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBfxGOYfGY1H",
    "outputId": "87cfa2d2-797c-4681-b0e5-c8d0f37dd632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.3172 - accuracy: 0.9005\n",
      "loss = 0.31722286343574524\n",
      "accuracy = 0.9004999995231628\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model_6.evaluate(test_datagen.flow(x_test, y_test_vec))\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
